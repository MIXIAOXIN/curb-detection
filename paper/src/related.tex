The problem of curb or \emph{step} detection has mainly been studied in the
context of Intelligent Transportation Systems (ITS), covering an extensive set
of sensing modalities and algorithms. In ITS, one might assume a typical
experimental setting where a car drives on a street and curbs are situated on
the left and right side of the vehicle. Therefore, most of these approaches
are inappropriate as such for a pedestrian robot navigating in cities. In this
situation, curbs will indeed appear under multiple viewpoints. We hence review
the main influential contributions to the field and relate them to our method.

In~\cite{oniga10polynomial}, Oniga \emph{et al.} employ a dense stereo-vision
system to capture a 3D point cloud, which is further transformed into a Digital
Elevation Map (DEM). Curbs are represented as third-order polynomials. Candidate
curb points are extracted with a Canny edge detector. A RANdom SAmple Consensus
(RANSAC) polynomial fitting is then applied to perform outlier rejection and
find the polynomial coefficients. The location of the curbs and their heights
are finally obtained with some further refinement steps. In comparison to this
method, we use the same measurement representation (DEM). However, we draw a
clear and sound probabilistic model from the sensing device to the curb
detection and limit the number of hand-tuned parameters.

Closer to our approach, Siegemund \emph{et al.}~\cite{siegemund10curb} proposed
a promising method that extracts curbs from dense stereo-vision data. We
actually take inspiration on their ideas and solve their major drawbacks. In
this paper, as mentioned above, they assume a strict environment model and they
lack a unified probabilistic model. Moreover, their curb models can only
represent a limited set of curbs. For instance, they cannot model T
junctions or roundabouts.

In~\cite{shin10drivable}, Shin \emph{et al.} use a similar setup as ours, i.e.,
a mobile robot equipped with a laser range-finder. They however stick to a
restricted environment model and their tilted laser only provides a single laser
line. Their algorithm is mostly engineered to fit their particular application
and setup, and again does not build on sound probabilistic model.

An alternative application of step detection is presented
in~\cite{pradeep08piece}. In this paper, Pradeep \emph{et al.} aim at mobility
aids for visually impaired people, as a complement to the white cane or the dog.
This naturally imposes restrictions in the sensing device, in this case a
wearable and cheap stereo camera. Their curb detection algorithm is based on the
same motivation as ours, i.e., building a piecewise planar model of the scene.
In their implementation, point-wise normal vectors are firstly estimated with
Principal Component Analysis on a local neighborhood and RANSAC for outlier
rejection. Tensor voting is then applied for finding globally consistent plane
normals and a final clustering step extracts the plane segments. Although it
solves many of the above issues, this method might also suffer from the lack of
any underlying probabilistic models.

In~\cite{yuan05dynamic}, Yuan and Manduchi also developed an algorithm for
visually impaired people, working with a custom sensing device called
a "Virtual White Cane". Their method uses a Jump-Markov Process to detect
geometric singularities in the range measurements. Despite its statistical
foundations, it will not generalize well to our application requirements and
provide a plane estimation.
